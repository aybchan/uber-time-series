{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter search for pretraining phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for import from `src` directory\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "from src import data\n",
    "from src import utils\n",
    "\n",
    "from models.encoder_decoder_dropout import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded\n",
      "43910 train rows from 2012-10-02 09:00:00 to 2017-10-05 23:00:00\n",
      "4320 valid rows from 2017-10-05 23:00:00 to 2018-04-03 23:00:00\n",
      "4321 test rows from 2018-04-03 23:00:00 to 2018-09-30 23:00:00\n",
      "16625 samples of 48 input steps and 12 output steps in train\n",
      "3534 samples of 48 input steps and 12 output steps in valid\n",
      "4020 samples of 48 input steps and 12 output steps in test\n"
     ]
    }
   ],
   "source": [
    "# fixed data parameters\n",
    "data_params = {\n",
    "    'n_input_steps': 48,\n",
    "    'n_output_steps': 12\n",
    "}\n",
    "\n",
    "# run the data preprocessing pipeline to create dataset\n",
    "_, _, samples = data.pipeline(data_params['n_input_steps'], data_params['n_output_steps'])\n",
    "datasets = data.get_datasets(samples, data_params['n_input_steps'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Bayesian optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get device\n",
    "\n",
    "GPU is recommended as this is a compute heavy job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to optimise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the `utils.train` and `utils.evaluate` to define the function to be optimised.\n",
    "\n",
    "This function takes in a dictionary of hyperparameters and returns the loss value on the validation data using the model trained according to the passed in hyperparameters. We want to know which hyperparameters will minimise this validation loss, so we will use `Ax` to do a guided search using Bayesian optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(params):\n",
    "    device = utils.get_device()\n",
    "    dataloaders = data.get_dataloaders(datasets, params.get('batch_size'))\n",
    "    in_features = dataloaders['train'].dataset.X.shape[-1]\n",
    "    model = VDEncoderDecoder(in_features=in_features, \n",
    "                             output_steps=params.get('n_output_steps', 12),\n",
    "                             p=params.get('variational_dropout_p')\n",
    "                            ).to(device)\n",
    "    model,_ = utils.train(device=device, model=model, dataloader=dataloaders['train'], params=params, use_tqdm=True)\n",
    "    return utils.evaluate(device=device, model=model, valid_loader=dataloaders['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `Ax` client\n",
    "\n",
    "We mainly follow the tutorial at https://ax.dev/tutorials/gpei_hartmann_service.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-09 20:34:46] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 2 decimal points.\n",
      "[INFO 09-09 20:34:46] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n"
     ]
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient\n",
    "\n",
    "ax_client = AxClient(enforce_sequential_optimization=False)\n",
    "\n",
    "# define hyperparameter bounds \n",
    "ax_client.create_experiment(\n",
    "    name='pretraining',\n",
    "    parameters=[\n",
    "        {\"name\": \"num_epochs\", \"type\": \"range\", \"bounds\": [150, 200]},\n",
    "        {\"name\": \"learning_rate\", \"type\": \"range\", \"bounds\": [5e-4, 1e-3], \"log_scale\": True},\n",
    "        {\"name\": \"batch_size\", \"type\": \"range\", \"bounds\": [64, 1024]},\n",
    "        {\"name\": \"variational_dropout_p\", \"type\": \"range\", \"bounds\": [0.2,0.5]}\n",
    "    ],\n",
    "    objective_name='loss',\n",
    "    minimize=True\n",
    ")\n",
    "\n",
    "def evaluate(parameters):\n",
    "    return {\"pretraining\": train_evaluate(parameters)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the optimisation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-09 20:34:58] ax.service.ax_client: Generated new trial 0 with parameters {'num_epochs': 189, 'learning_rate': 0.0, 'batch_size': 586, 'variational_dropout_p': 0.3}.\n",
      "Epoch=188 | [16625|16625]\tloss=1.2536: 100%|██████████| 189/189 [03:30<00:00,  1.11s/it]\n",
      "[INFO 09-09 20:38:31] ax.service.ax_client: Completed trial 0 with data: {'loss': (1.23, None)}.\n",
      "[INFO 09-09 20:38:31] ax.service.ax_client: Generated new trial 1 with parameters {'num_epochs': 195, 'learning_rate': 0.0, 'batch_size': 999, 'variational_dropout_p': 0.49}.\n",
      "Epoch=194 | [16625|16625]\tloss=1.4263: 100%|██████████| 195/195 [03:06<00:00,  1.04it/s]\n",
      "[INFO 09-09 20:41:38] ax.service.ax_client: Completed trial 1 with data: {'loss': (0.69, None)}.\n",
      "[INFO 09-09 20:41:38] ax.service.ax_client: Generated new trial 2 with parameters {'num_epochs': 152, 'learning_rate': 0.0, 'batch_size': 186, 'variational_dropout_p': 0.41}.\n",
      "Epoch=151 | [16625|16625]\tloss=1.3494: 100%|██████████| 152/152 [05:25<00:00,  2.14s/it]\n",
      "[INFO 09-09 20:47:04] ax.service.ax_client: Completed trial 2 with data: {'loss': (0.82, None)}.\n",
      "[INFO 09-09 20:47:04] ax.service.ax_client: Generated new trial 3 with parameters {'num_epochs': 184, 'learning_rate': 0.0, 'batch_size': 793, 'variational_dropout_p': 0.23}.\n",
      "Epoch=183 | [16625|16625]\tloss=0.9190: 100%|██████████| 184/184 [02:57<00:00,  1.04it/s]\n",
      "[INFO 09-09 20:50:02] ax.service.ax_client: Completed trial 3 with data: {'loss': (0.34, None)}.\n",
      "[INFO 09-09 20:50:02] ax.service.ax_client: Generated new trial 4 with parameters {'num_epochs': 166, 'learning_rate': 0.0, 'batch_size': 723, 'variational_dropout_p': 0.47}.\n",
      "Epoch=165 | [16625|16625]\tloss=1.4850: 100%|██████████| 166/166 [02:48<00:00,  1.02s/it]\n",
      "[INFO 09-09 20:52:51] ax.service.ax_client: Completed trial 4 with data: {'loss': (0.72, None)}.\n",
      "[INFO 09-09 20:52:52] ax.service.ax_client: Generated new trial 5 with parameters {'num_epochs': 183, 'learning_rate': 0.0, 'batch_size': 878, 'variational_dropout_p': 0.22}.\n",
      "Epoch=182 | [16625|16625]\tloss=0.7896: 100%|██████████| 183/183 [02:54<00:00,  1.05it/s]\n",
      "[INFO 09-09 20:55:46] ax.service.ax_client: Completed trial 5 with data: {'loss': (0.29, None)}.\n",
      "[INFO 09-09 20:55:46] ax.service.ax_client: Generated new trial 6 with parameters {'num_epochs': 174, 'learning_rate': 0.0, 'batch_size': 833, 'variational_dropout_p': 0.2}.\n",
      "Epoch=173 | [16625|16625]\tloss=0.7152: 100%|██████████| 174/174 [02:50<00:00,  1.02it/s]\n",
      "[INFO 09-09 20:58:37] ax.service.ax_client: Completed trial 6 with data: {'loss': (0.27, None)}.\n",
      "[INFO 09-09 20:58:38] ax.service.ax_client: Generated new trial 7 with parameters {'num_epochs': 180, 'learning_rate': 0.0, 'batch_size': 1004, 'variational_dropout_p': 0.2}.\n",
      "Epoch=179 | [16625|16625]\tloss=0.6918: 100%|██████████| 180/180 [02:46<00:00,  1.08it/s]\n",
      "[INFO 09-09 21:01:25] ax.service.ax_client: Completed trial 7 with data: {'loss': (0.26, None)}.\n",
      "[INFO 09-09 21:01:26] ax.service.ax_client: Generated new trial 8 with parameters {'num_epochs': 173, 'learning_rate': 0.0, 'batch_size': 1007, 'variational_dropout_p': 0.24}.\n",
      "Epoch=172 | [16625|16625]\tloss=0.9025: 100%|██████████| 173/173 [02:40<00:00,  1.08it/s]\n",
      "[INFO 09-09 21:04:06] ax.service.ax_client: Completed trial 8 with data: {'loss': (0.29, None)}.\n",
      "[INFO 09-09 21:04:07] ax.service.ax_client: Generated new trial 9 with parameters {'num_epochs': 177, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.2}.\n",
      "Epoch=176 | [16625|16625]\tloss=0.7540: 100%|██████████| 177/177 [02:45<00:00,  1.07it/s]\n",
      "[INFO 09-09 21:06:52] ax.service.ax_client: Completed trial 9 with data: {'loss': (0.25, None)}.\n",
      "[INFO 09-09 21:06:53] ax.service.ax_client: Generated new trial 10 with parameters {'num_epochs': 180, 'learning_rate': 0.0, 'batch_size': 943, 'variational_dropout_p': 0.2}.\n",
      "Epoch=179 | [16625|16625]\tloss=0.6982: 100%|██████████| 180/180 [02:50<00:00,  1.06it/s]\n",
      "[INFO 09-09 21:09:43] ax.service.ax_client: Completed trial 10 with data: {'loss': (0.34, None)}.\n",
      "[INFO 09-09 21:09:44] ax.service.ax_client: Generated new trial 11 with parameters {'num_epochs': 162, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.2}.\n",
      "Epoch=161 | [16625|16625]\tloss=0.8653: 100%|██████████| 162/162 [02:31<00:00,  1.07it/s]\n",
      "[INFO 09-09 21:12:15] ax.service.ax_client: Completed trial 11 with data: {'loss': (0.23, None)}.\n",
      "[INFO 09-09 21:12:16] ax.service.ax_client: Generated new trial 12 with parameters {'num_epochs': 156, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.2}.\n",
      "Epoch=155 | [16625|16625]\tloss=0.7598: 100%|██████████| 156/156 [02:24<00:00,  1.08it/s]\n",
      "[INFO 09-09 21:14:40] ax.service.ax_client: Completed trial 12 with data: {'loss': (0.42, None)}.\n",
      "[INFO 09-09 21:14:41] ax.service.ax_client: Generated new trial 13 with parameters {'num_epochs': 170, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.21}.\n",
      "Epoch=169 | [16625|16625]\tloss=0.7368: 100%|██████████| 170/170 [02:38<00:00,  1.07it/s]\n",
      "[INFO 09-09 21:17:20] ax.service.ax_client: Completed trial 13 with data: {'loss': (0.28, None)}.\n",
      "[INFO 09-09 21:17:21] ax.service.ax_client: Generated new trial 14 with parameters {'num_epochs': 164, 'learning_rate': 0.0, 'batch_size': 773, 'variational_dropout_p': 0.21}.\n",
      "Epoch=163 | [16625|16625]\tloss=0.7944: 100%|██████████| 164/164 [02:43<00:00,  1.00it/s]\n",
      "[INFO 09-09 21:20:04] ax.service.ax_client: Completed trial 14 with data: {'loss': (0.24, None)}.\n",
      "[INFO 09-09 21:20:05] ax.service.ax_client: Generated new trial 15 with parameters {'num_epochs': 161, 'learning_rate': 0.0, 'batch_size': 943, 'variational_dropout_p': 0.24}.\n",
      "Epoch=160 | [16625|16625]\tloss=0.9341: 100%|██████████| 161/161 [02:32<00:00,  1.06it/s]\n",
      "[INFO 09-09 21:22:37] ax.service.ax_client: Completed trial 15 with data: {'loss': (0.3, None)}.\n",
      "[INFO 09-09 21:22:38] ax.service.ax_client: Generated new trial 16 with parameters {'num_epochs': 169, 'learning_rate': 0.0, 'batch_size': 908, 'variational_dropout_p': 0.2}.\n",
      "Epoch=168 | [16625|16625]\tloss=0.6845: 100%|██████████| 169/169 [02:40<00:00,  1.06it/s]\n",
      "[INFO 09-09 21:25:18] ax.service.ax_client: Completed trial 16 with data: {'loss': (0.23, None)}.\n",
      "[INFO 09-09 21:25:19] ax.service.ax_client: Generated new trial 17 with parameters {'num_epochs': 151, 'learning_rate': 0.0, 'batch_size': 877, 'variational_dropout_p': 0.2}.\n",
      "Epoch=150 | [16625|16625]\tloss=0.7350: 100%|██████████| 151/151 [02:24<00:00,  1.04it/s]\n",
      "[INFO 09-09 21:27:44] ax.service.ax_client: Completed trial 17 with data: {'loss': (0.27, None)}.\n",
      "[INFO 09-09 21:27:45] ax.service.ax_client: Generated new trial 18 with parameters {'num_epochs': 163, 'learning_rate': 0.0, 'batch_size': 476, 'variational_dropout_p': 0.2}.\n",
      "Epoch=162 | [16625|16625]\tloss=0.5839: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it]\n",
      "[INFO 09-09 21:30:51] ax.service.ax_client: Completed trial 18 with data: {'loss': (0.37, None)}.\n",
      "[INFO 09-09 21:30:52] ax.service.ax_client: Generated new trial 19 with parameters {'num_epochs': 160, 'learning_rate': 0.0, 'batch_size': 920, 'variational_dropout_p': 0.2}.\n",
      "Epoch=159 | [16625|16625]\tloss=0.8008: 100%|██████████| 160/160 [02:30<00:00,  1.07it/s]\n",
      "[INFO 09-09 21:33:22] ax.service.ax_client: Completed trial 19 with data: {'loss': (0.26, None)}.\n",
      "[INFO 09-09 21:33:23] ax.service.ax_client: Generated new trial 20 with parameters {'num_epochs': 150, 'learning_rate': 0.0, 'batch_size': 636, 'variational_dropout_p': 0.2}.\n",
      "Epoch=149 | [16625|16625]\tloss=0.6615: 100%|██████████| 150/150 [02:37<00:00,  1.05s/it]\n",
      "[INFO 09-09 21:36:01] ax.service.ax_client: Completed trial 20 with data: {'loss': (0.29, None)}.\n",
      "[INFO 09-09 21:36:02] ax.service.ax_client: Generated new trial 21 with parameters {'num_epochs': 200, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.28}.\n",
      "Epoch=199 | [16625|16625]\tloss=1.0154: 100%|██████████| 200/200 [03:04<00:00,  1.08it/s]\n",
      "[INFO 09-09 21:39:07] ax.service.ax_client: Completed trial 21 with data: {'loss': (0.37, None)}.\n",
      "[INFO 09-09 21:39:08] ax.service.ax_client: Generated new trial 22 with parameters {'num_epochs': 200, 'learning_rate': 0.0, 'batch_size': 1024, 'variational_dropout_p': 0.2}.\n",
      "Epoch=199 | [16625|16625]\tloss=0.6399: 100%|██████████| 200/200 [03:05<00:00,  1.08it/s]\n",
      "[INFO 09-09 21:42:14] ax.service.ax_client: Completed trial 22 with data: {'loss': (0.21, None)}.\n",
      "[INFO 09-09 21:42:15] ax.service.ax_client: Generated new trial 23 with parameters {'num_epochs': 200, 'learning_rate': 0.0, 'batch_size': 716, 'variational_dropout_p': 0.2}.\n",
      "Epoch=199 | [16625|16625]\tloss=0.6739: 100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n",
      "[INFO 09-09 21:45:38] ax.service.ax_client: Completed trial 23 with data: {'loss': (0.23, None)}.\n",
      "[INFO 09-09 21:45:39] ax.service.ax_client: Generated new trial 24 with parameters {'num_epochs': 200, 'learning_rate': 0.0, 'batch_size': 957, 'variational_dropout_p': 0.2}.\n",
      "Epoch=199 | [16625|16625]\tloss=0.7593: 100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
      "[INFO 09-09 21:48:48] ax.service.ax_client: Completed trial 24 with data: {'loss': (0.26, None)}.\n",
      "[INFO 09-09 21:48:48] ax.service.ax_client: Generated new trial 25 with parameters {'num_epochs': 200, 'learning_rate': 0.0, 'batch_size': 314, 'variational_dropout_p': 0.2}.\n",
      "Epoch=127 | [ 2512|16625]\tloss=0.7746:  64%|██████▎   | 127/200 [03:05<01:45,  1.45s/it]"
     ]
    }
   ],
   "source": [
    "# run 30 jobs\n",
    "for i in range(30):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters)['pretraining']['loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_epochs': 200,\n",
       "  'learning_rate': 0.0009002389954280866,\n",
       "  'batch_size': 64,\n",
       "  'variational_dropout_p': 0.2000000000364784},\n",
       " ({'loss': 0.19481891684816835}, {'loss': {'loss': 0.00042067191742800174}}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.get_best_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-09 23:22:21] ax.service.ax_client: Saved JSON-serialized state of optimization to `ax_client_snapshot.json`.\n"
     ]
    }
   ],
   "source": [
    "ax_client.save_to_json_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
