{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluation\n",
    "\n",
    "In this notebook, we compare the prediction results on the test set from the Uber model to predictions from Facebook's Prophet Bayesian time series forecasting package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded\n",
      "\n",
      "43910 train rows from 2012-10-02 09:00:00 to 2017-10-05 23:00:00\n",
      "4320 valid rows from 2017-10-05 23:00:00 to 2018-04-03 23:00:00\n",
      "4321 test rows from 2018-04-03 23:00:00 to 2018-09-30 23:00:00\n",
      "\n",
      "17341 samples of 48 input steps and 4 output steps in train\n",
      "3622 samples of 48 input steps and 4 output steps in valid\n",
      "4060 samples of 48 input steps and 4 output steps in test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# allows for import from `src` directory\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "from src import data\n",
    "from src import utils\n",
    "from src import inference\n",
    "from src import evaluation\n",
    "\n",
    "from models.predict import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "params = utils.read_json_params('../parameters.json')\n",
    "df, dataloaders = data.full_pipeline(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Get Uber results\n",
    "\n",
    "Run the Uber inference algorithm and rescale the results back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal(a, b, tol=1):\n",
    "    a,b = int(a),int(b)\n",
    "    return np.allclose(a,b,rtol=1)\n",
    "\n",
    "def reinflate(df, inference_results):\n",
    "    Y, Y_hat, Y_hat_2upper, Y_hat_2lower, Y_hat_upper, Y_hat_lower = inference_results\n",
    "    \n",
    "    X_orig = df['traffic_volume'].values\n",
    "    Y_test = Y\n",
    "    steps = 5\n",
    "    windows = np.lib.stride_tricks.as_strided(X_orig, shape=[len(X_orig)-steps+1, steps], strides=(8,8))\n",
    "    test_start_idx = np.where((Y_test[:steps] ==  windows).all(axis=1))[0][0]\n",
    "\n",
    "    results = []\n",
    "    idx = 0\n",
    "    for r,row in enumerate(df[['traffic_volume']].iloc[test_start_idx:].itertuples()):\n",
    "        try:\n",
    "            if np.isnan(row.traffic_volume):\n",
    "                continue\n",
    "            else:\n",
    "                if equal(row.traffic_volume, Y_test[idx]):\n",
    "                    results.append([row.Index, Y_test[idx], Y_hat[idx], Y_hat_2upper[idx], Y_hat_2lower[idx], Y_hat_upper[idx], Y_hat_lower[idx]])\n",
    "                    idx +=1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df_inference = pd.DataFrame(np.vstack(results))\n",
    "    full_dates = pd.DataFrame(pd.date_range(results[0][0], results[-1][0], freq='H'))\n",
    "    df_inference = df_inference.merge(full_dates, left_on=0, right_on=0, how='right')\n",
    "    cols = ['datetime','Y', 'Y_hat', 'Y_hat_2upper', 'Y_hat_2lower', 'Y_hat_upper', 'Y_hat_lower']\n",
    "    df_inference = df_inference.rename({i:cols[i] for i in np.arange(df_inference.shape[-1])}, axis=1).set_index(cols[0])\n",
    "    df_inference = df_inference.astype({col: np.float64 for col in df_inference.columns})\n",
    "    \n",
    "    return df_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:01<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "results = inference.run(params, dataloaders)\n",
    "Y, Y_hat, Y_hat_2upper, Y_hat_2lower, Y_hat_upper, Y_hat_lower = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber = reinflate(df, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Facebook Prophet\n",
    "\n",
    "For comparision to the model we have implemented, we will train Faceook's Prophet with the training and validation dataset, then use it for predictions on the test set. We will then evaluate and compare performance with a range of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fbprophet\n",
    "\n",
    "# copy the data up to the end of validation set from df to a new prophet friendly dataframe\n",
    "test_start = '2018-04-05 23:00:00'\n",
    "test_end = '2018-09-28 20:00:00'\n",
    "\n",
    "df_for_prophet = (df.reset_index()[['date_time','traffic_volume']]\n",
    "                .rename({'date_time': 'ds', 'traffic_volume': 'y'}, axis=1))\n",
    "df_for_prophet = df_for_prophet[df_for_prophet['ds'] < test_start]\n",
    "prophet = fbprophet.Prophet()\n",
    "_ = prophet.fit(df_for_prophet) # 23:22:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a range of hourly datetime values over the test dataset date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_hours = int((np.datetime64(test_end) - np.datetime64(test_start)) /  \n",
    "                   np.timedelta64(60*60,'s')) + 1\n",
    "future = prophet.make_future_dataframe(periods=n_test_hours,freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = prophet.predict(future)\n",
    "df_prophet = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "df_prophet = df_prophet[df_prophet['ds'] >= test_start].set_index('ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_uber.Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t | MAE\n",
      "Uber     | 280.4710\n",
      "Prophet  | 680.9752\n"
     ]
    }
   ],
   "source": [
    "print('\\t | MAE')\n",
    "for label,predictions in zip(['Uber', 'Prophet'], [df_uber.Y_hat, df_prophet.yhat]):\n",
    "    print(f'{label:8s} | {evaluation.mae(y,predictions.values):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t | RMSE\n",
      "Uber     | 490.9205\n",
      "Prophet  | 955.8478\n"
     ]
    }
   ],
   "source": [
    "print('\\t | RMSE')\n",
    "for label,predictions in zip(['Uber', 'Prophet'], [df_uber.Y_hat, df_prophet.yhat]):\n",
    "    print(f'{label:8s} | {evaluation.rmse(y,predictions.values):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t | MAPE\n",
      "Uber     | 0.1299\n",
      "Prophet  | 0.4125\n"
     ]
    }
   ],
   "source": [
    "print('\\t | MAPE')\n",
    "for label,predictions in zip(['Uber', 'Prophet'], [df_uber.Y_hat, df_prophet.yhat]):\n",
    "    print(f'{label:8s} | {evaluation.mape(y,predictions.values):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t | SMAPE\n",
      "Uber     | 0.0289\n",
      "Prophet  | 0.0243\n"
     ]
    }
   ],
   "source": [
    "print('\\t | SMAPE')\n",
    "for label,predictions in zip(['Uber', 'Prophet'], [df_uber.Y_hat, df_prophet.yhat]):\n",
    "    print(f'{label:8s} | {evaluation.smape(y,predictions.values):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
